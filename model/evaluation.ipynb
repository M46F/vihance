{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cntk\n",
      "  Downloading https://files.pythonhosted.org/packages/63/b4/7396dabbaa8125d8ea8fc25cc360667b773f3f82ecf63fbadf07ac12c924/cntk-2.5.1-cp35-cp35m-win_amd64.whl (63.7MB)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\aldi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cntk)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\aldi\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cntk)\n",
      "Installing collected packages: cntk\n",
      "Successfully installed cntk-2.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install cntk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU unavailable. Using CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import cntk as C\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib\n",
    "from scipy.misc import imsave\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve, urlopen\n",
    "\n",
    "try:\n",
    "    C.device.try_set_default_device(C.device.gpu(0))\n",
    "except:\n",
    "    print(\"GPU unavailable. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Determine the data path for testing\n",
    "# Check for an environment variable defined in CNTK's test infrastructure\n",
    "envvar = 'CNTK_EXTERNAL_TESTDATA_SOURCE_DIRECTORY'\n",
    "def is_test(): \n",
    "    return envvar in os.environ\n",
    "\n",
    "if is_test():\n",
    "    test_data_path_base = os.path.join(os.environ[envvar], \"Tutorials\", \"data\")\n",
    "    test_data_dir = os.path.join(test_data_path_base, \"BerkeleySegmentationDataset\")\n",
    "    test_data_dir = os.path.normpath(test_data_dir)\n",
    "\n",
    "#prefer our default path for the data\n",
    "data_dir = os.path.join(\"data\", \"BerkeleySegmentationDataset\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "#folder with images to be evaluated\n",
    "example_folder = os.path.join(data_dir, \"example_images\")\n",
    "if not os.path.exists(example_folder):\n",
    "    os.makedirs(example_folder)\n",
    "\n",
    "#folders with resulting images\n",
    "results_folder = os.path.join(data_dir, \"example_results\")\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "#names of used models\n",
    "model_names = [\"VDSR\", \"DRNN\", \"SRResNet\", \"SRGAN\"]\n",
    "\n",
    "#output dimensions of models respectively (assumed that output is a square)\n",
    "output_dims = [64, 64, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#model - the model for super-resolution\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "#output_dims - dimensions of current model output image\n",
    "#            - it is assumed that model output image is a square\n",
    "\n",
    "#pre_upscale - if True, image will be upscaled by a specified factor with bicubic interpolation at the start\n",
    "#            - the resulting image then replaces the original one in the next operations\n",
    "#            - if False, that step is skipped\n",
    "#            - this should be set on True for models which are clearing up the image and don't make upscaling by themselves\n",
    "\n",
    "#clear_up - if True, the forwarded image will be cleared up by the model and not upscaled\n",
    "#         - this is important to know because step variables are different then (see code)\n",
    "#         - notice that we exit the function if pre_upscale is True and clear_up false because if image was pre-upscaled,\n",
    "#           it should be cleared up afterwards\n",
    "\n",
    "#residual_model - is the model learning residual image only (the difference between blurry and original patch)?\n",
    "#               - if true, residual is added to the low resolutin image to produce the result\n",
    "#               - otherwise, we only need to scale back the result (see code below)\n",
    "def evaluate(filename, model, outfile, output_dims, pre_upscale = False, clear_up = False, residual_model = False):\n",
    "    img = Image.open(filename)\n",
    "\n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "\n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "\n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "\n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "\n",
    "    #situation which should not occur, if we need preprocess, we will need to clear up the result\n",
    "    if((pre_upscale) and (not clear_up)):\n",
    "        print(\"Pre-magnified image is not being cleared up.\")\n",
    "        return\n",
    "\n",
    "    #pre-magnify picture if needed\n",
    "    if(pre_upscale):\n",
    "        img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "\n",
    "    #if the current image is being cleared up with no further uspcaling,\n",
    "    #set coef to 1 and other parameters accordingly\n",
    "    if(clear_up):\n",
    "        result = np.zeros((img.height, img.width, 3))\n",
    "        range_x = output_dims\n",
    "        range_y = output_dims\n",
    "        step_x = range_x - 2 * offset\n",
    "        step_y = range_y - 2 * offset\n",
    "        coef = 1\n",
    "    #otherwise, set result to be coef (2 by default) times larger than image\n",
    "    else:\n",
    "        result = np.zeros((coef * img.height, coef * img.width, 3))\n",
    "\n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "\n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "\n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = np.squeeze(model.eval({model.arguments[0] : [rgb_patch]}))\n",
    "\n",
    "            img1 = np.ascontiguousarray(rgb_patch.transpose(2, 1, 0))\n",
    "            img2 = np.ascontiguousarray(pred.transpose(2, 1, 0))\n",
    "\n",
    "            #if model predicts residual image,\n",
    "            #scale back the prediction and add to starting patch\n",
    "            #otherwise just scale back\n",
    "            if(residual_model):\n",
    "                img2 = 255.0 * img2 + img1\n",
    "            else:\n",
    "                img2 = pred.transpose(2, 1, 0)\n",
    "                img2 = img2 * 255.0\n",
    "\n",
    "            # make sure img2 is C Contiguous as we just transposed it\n",
    "            img2 = np.ascontiguousarray(img2)\n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = C.relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "\n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "\n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "\n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "\n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad right\n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "\n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "\n",
    "    result = np.ascontiguousarray(result)\n",
    "\n",
    "    #save result\n",
    "    imsave(outfile, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory data\\BerkeleySegmentationDataset\\PretrainedModels\n",
      "Image directory data\\BerkeleySegmentationDataset\\Images\n"
     ]
    }
   ],
   "source": [
    "#Get the path for pre-trained models and example images\n",
    "if is_test():\n",
    "    models_dir = os.path.join(test_data_dir, \"PretrainedModels\")\n",
    "    image_dir = os.path.join(test_data_dir, \"Images\")\n",
    "else:\n",
    "    models_dir = os.path.join(data_dir, \"PretrainedModels\")\n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    image_dir = os.path.join(data_dir, \"Images\")\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "\n",
    "print(\"Model directory\", models_dir)\n",
    "print(\"Image directory\", image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached VDSR model\n",
      "Using cached DRNN.model\n",
      "Using cached SRResNet.model\n",
      "Using cached SRGAN model\n",
      "Loading pretrained models...\n",
      "Loaded pretrained models.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(os.path.join(models_dir, \"VDSR.model\")):\n",
    "    print(\"Downloading VDSR model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/VDSR.model\", os.path.join(models_dir, \"VDSR.model\"))\n",
    "else:\n",
    "    print(\"Using cached VDSR model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"DRNN.model\")):\n",
    "    print(\"Downloading DRNN model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/DRNN.model\", os.path.join(models_dir, \"DRNN.model\"))\n",
    "else:\n",
    "    print(\"Using cached DRNN.model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"SRResNet.model\")):\n",
    "    print(\"Downloading SRResNet model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/SRResNet.model\", os.path.join(models_dir, \"SRResNet.model\"))\n",
    "else:\n",
    "    print(\"Using cached SRResNet.model\")\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"SRGAN.model\")):\n",
    "    print(\"Downloading SRGAN model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/SRGAN.model\", os.path.join(models_dir, \"SRGAN.model\"))\n",
    "else:\n",
    "    print(\"Using cached SRGAN model\")\n",
    "\n",
    "print(\"Loading pretrained models...\")\n",
    "VDSR_model = C.load_model(os.path.join(models_dir, \"VDSR.model\"))\n",
    "DRNN_model = C.load_model(os.path.join(models_dir, \"DRNN.model\"))\n",
    "SRResNet_model = C.load_model(os.path.join(models_dir, \"SRResNet.model\"))\n",
    "SRGAN_model = C.load_model(os.path.join(models_dir, \"SRGAN.model\"))\n",
    "\n",
    "models = [VDSR_model, DRNN_model, SRResNet_model, SRGAN_model]\n",
    "\n",
    "print(\"Loaded pretrained models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading example image ...\n"
     ]
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "if not os.path.isfile(os.path.join(image_dir, \"253027.jpg\")):\n",
    "    print(\"Downloading example image ...\")\n",
    "    link = \"https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/segbench/BSDS300/html/images/plain/normal/color/253027.jpg\"\n",
    "    urlretrieve(link, os.path.join(example_folder, \"253027.jpg\"))\n",
    "else:\n",
    "    print(\"Using cached image file\")\n",
    "    copyfile(os.path.join(image_dir, \"253027.jpg\"), os.path.join(example_folder, \"253027.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_folder = os.path.join(results_folder, \"bicubic\")\n",
    "\n",
    "#upscale by bicubic and save for reference\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    img = Image.open(filename)\n",
    "    out = img.resize((2 * img.width, 2 * img.height), Image.BICUBIC)\n",
    "    out.save(os.path.join(save_folder, entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_results\\1525878424968.jpg\n",
      "Time is 14.570973634719849 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_VDSR_results\\1525878424968.jpg\n",
      "Time is 14.035000801086426 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_VDSR_results\\253027.jpg\n",
      "Time is 10.227000713348389 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_VDSR_results\\950373.jpg\n",
      "Time is 2.0739994049072266 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_VDSR_results\\1525878424968.jpg\n",
      "Time is 43.64300608634949 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_VDSR_results\\253027.jpg\n",
      "Time is 30.07200527191162 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_VDSR_results\\950373.jpg\n",
      "Time is 5.972002744674683 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_results\\1525878424968.jpg\n",
      "Time is 42.817482233047485 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_DRNN_results\\1525878424968.jpg\n",
      "Time is 14.167518377304077 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_DRNN_results\\253027.jpg\n",
      "Time is 10.195001363754272 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_DRNN_results\\950373.jpg\n",
      "Time is 2.1020009517669678 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_DRNN_results\\1525878424968.jpg\n",
      "Time is 43.68033456802368 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_DRNN_results\\253027.jpg\n",
      "Time is 30.667004823684692 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_DRNN_results\\950373.jpg\n",
      "Time is 6.011001110076904 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\SRResNet_results\\1525878424968.jpg\n",
      "Time is 23.850640058517456 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRResNet_results\\1525878424968.jpg\n",
      "Time is 14.519002676010132 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRResNet_results\\253027.jpg\n",
      "Time is 10.134000062942505 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRResNet_results\\950373.jpg\n",
      "Time is 1.9610018730163574 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRResNet_results\\1525878424968.jpg\n",
      "Time is 43.88216757774353 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRResNet_results\\253027.jpg\n",
      "Time is 32.049328565597534 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRResNet_results\\950373.jpg\n",
      "Time is 6.052001476287842 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\SRGAN_results\\1525878424968.jpg\n",
      "Time is 23.533002376556396 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRGAN_results\\1525878424968.jpg\n",
      "Time is 15.392096281051636 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRGAN_results\\253027.jpg\n",
      "Time is 10.099003314971924 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\VDSR_SRGAN_results\\950373.jpg\n",
      "Time is 1.97999906539917 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRGAN_results\\1525878424968.jpg\n",
      "Time is 43.82151389122009 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRGAN_results\\253027.jpg\n",
      "Time is 29.969003915786743 ms\n",
      "Now creating: data\\BerkeleySegmentationDataset\\example_results\\DRNN_SRGAN_results\\950373.jpg\n",
      "Time is 5.94800066947937 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#loop thorugh every model\n",
    "for i in range(4):\n",
    "    save_folder = os.path.join(results_folder, model_names[i] + \"_results\")\n",
    "\n",
    "    #loop through every image in example_folder\n",
    "    for entry in os.listdir(example_folder):\n",
    "        filename = os.path.join(example_folder, entry)\n",
    "\n",
    "        if not os.path.exists(save_folder):\n",
    "            os.makedirs(save_folder)\n",
    "\n",
    "        outfile = os.path.join(save_folder, entry)\n",
    "\n",
    "        t = time.time()\n",
    "        print(\"Now creating: \" + outfile)\n",
    "\n",
    "        #function calls for different models\n",
    "        if(i < 2):\n",
    "            #residual learning, image is pre-upscaled and then cleared up\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = True, clear_up = True, residual_model = True)\n",
    "        else:\n",
    "            #all upscaling is within the model\n",
    "            evaluate(filename, models[i], outfile, output_dims[i], pre_upscale = False, clear_up = False, residual_model = False)\n",
    "            \n",
    "        print(\"Time is {} ms\".format(time.time() - t))\n",
    "\n",
    "    #loop through models which can additionally clear up image after we increased it (DRNN and VDSR)\n",
    "    for j in range(2):\n",
    "        #loop through results of previously applied model\n",
    "        for entry in os.listdir(save_folder):\n",
    "            filename = os.path.join(save_folder, entry)\n",
    "            filter_folder = os.path.join(results_folder, model_names[j] + \"_\" + model_names[i] + \"_results\")\n",
    "\n",
    "            if not os.path.exists(filter_folder):\n",
    "                os.makedirs(filter_folder)\n",
    "\n",
    "            outfile = os.path.join(filter_folder, entry)\n",
    "\n",
    "            t = time.time()\n",
    "            print(\"Now creating: \" + outfile)\n",
    "\n",
    "            #additionally clear up image without pre-magnifying\n",
    "            evaluate(filename, models[j], outfile, output_dims[j], pre_upscale = False, clear_up = True, residual_model = True)\n",
    "            print(\"Time is {} ms\".format(time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
