{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib\n",
    "from scipy.misc import imsave\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve, urlopen\n",
    "\n",
    "try:\n",
    "    C.device.try_set_default_device(C.device.gpu(0))\n",
    "except:\n",
    "    print(\"GPU unavailable. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "def evaluate(model, img):\n",
    "    output_dims = 64\n",
    "\n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "\n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "\n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "\n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "\n",
    "    img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "\n",
    "    result = np.zeros((img.height, img.width, 3))\n",
    "    range_x = output_dims\n",
    "    range_y = output_dims\n",
    "    step_x = range_x - 2 * offset\n",
    "    step_y = range_y - 2 * offset\n",
    "    coef = 1\n",
    "\n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "\n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "\n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = model.predict(rgb_patch.transpose(2,1,0).reshape(1,64,64,3))\n",
    "\n",
    "            img2 = pred.reshape(64,64,3)\n",
    "\n",
    "            # make sure img2 is C Contiguous as we just transposed it\n",
    "            img2 = np.ascontiguousarray(img2)\n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = C.relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "\n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "\n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "\n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "\n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad right\n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "\n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "\n",
    "    result = np.ascontiguousarray(result)\n",
    "\n",
    "    #save result\n",
    "    return result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "dict_of_vid= {\n",
    "    'vid_3_360.mp4':{'fps':0,'data':[]},\n",
    "    'vid_2_360.mp4':{'fps':0,'data':[]},\n",
    "    'vid_1_360.mp4':{'fps':0,'data':[]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in dict_of_vid:\n",
    "    vidcap = cv2.VideoCapture(f)\n",
    "    fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
    "    dict_of_vid[f]['fps'] = fps\n",
    "    success,image = vidcap.read()\n",
    "    while success:\n",
    "        img = Image.fromarray(image, mode='RGB')\n",
    "        dict_of_vid[f]['data'].append(img)\n",
    "        success,image = vidcap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aldi\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('..//Prediction//data//vihance//Models//vdsr_trained.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate_vid(f, fps, data):\n",
    "    print(\"processing\", f)\n",
    "    print(\"len\",str(len(data)))\n",
    "    first = True\n",
    "    fourcc = None\n",
    "    out = None\n",
    "    enhanced = []\n",
    "    bicubic = []\n",
    "    bicubic_file = 'bicubic_' + str(f.split('.')[0])\n",
    "    enhanced_file = 'enhanced_' + str(f.split('.')[0])\n",
    "    ct = 0\n",
    "    for d in data:\n",
    "        print('enhanced',str(ct))\n",
    "        ct+=1\n",
    "        enhc = evaluate(model, d)\n",
    "        bgr_img = np.array(d, dtype = np.uint8)\n",
    "        rgb_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)\n",
    "        bic_img = Image.fromarray(rgb_img, mode='RGB')\n",
    "        bic = bic_img.resize((2 * bic_img.width, 2 * bic_img.height), Image.BICUBIC)\n",
    "\n",
    "        enhanced.append(enhc)\n",
    "        bicubic.append(bic)\n",
    "        cv2.imwrite('./enhanced/{}{}.jpg'.format(f.split('.')[0], ct), enhc)\n",
    "        with open('./bicubic/{}{}.jpg'.format(f.split('.')[0], ct), 'w') as fss:\n",
    "            bic.save(fss)\n",
    "        if ct == fps*5:\n",
    "            break\n",
    "    print(\"done enhance\")\n",
    "    try:\n",
    "        for enhc in enhanced:\n",
    "            if first:\n",
    "                h,w,c = enhc.shape\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                out = cv2.VideoWriter('{}.avi'.format(enhanced_file), fourcc, fps, (w, h))\n",
    "                first = False\n",
    "            print('write',str(ct))\n",
    "            ct+=1\n",
    "            out.write(enhc)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        first = True\n",
    "        print(\"DONE WRITING ENHANCED\")\n",
    "        for bic in bicubic:\n",
    "            if first:\n",
    "                h,w,c = bic.shape\n",
    "                fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "                out = cv2.VideoWriter('{}.avi'.format(bicubic_file), fourcc, fps, (w, h))\n",
    "                first = False\n",
    "            print('write',str(ct))\n",
    "            ct+=1\n",
    "            out.write(bic)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"DONE WRITING ENHANCED\")\n",
    "        return (enhanced, bicubic)\n",
    "    except:\n",
    "        print(\"\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fails = []\n",
    "for f in dict_of_vid:\n",
    "    fails.append(evaluate_vid(f,  dict_of_vid[f]['fps'], dict_of_vid[f]['data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
