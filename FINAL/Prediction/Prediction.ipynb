{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import urllib\n",
    "from scipy.misc import imsave\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve, urlopen\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve, urlopen\n",
    "\n",
    "try:\n",
    "    C.device.try_set_default_device(C.device.gpu(0))\n",
    "except:\n",
    "    print(\"GPU unavailable. Using CPU instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prefer our default path for the data\n",
    "data_dir = os.path.join(\"data\", \"vihance\")\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "#folder with images to be evaluated\n",
    "example_folder = os.path.join(data_dir, \"example_images\")\n",
    "if not os.path.exists(example_folder):\n",
    "    os.makedirs(example_folder)\n",
    "\n",
    "#folders with resulting images\n",
    "results_folder = os.path.join(data_dir, \"example_results\")\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "    \n",
    "#folders with VDSR models\n",
    "models_dir = os.path.join(data_dir, \"Models\")\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aldi\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using CNTK backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached VDSR model\n",
      "Loading models...\n",
      "Loaded pretrained models.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "if not os.path.isfile(os.path.join(models_dir, \"VDSR.model\")):\n",
    "    print(\"Downloading VDSR model...\")\n",
    "    urlretrieve(\"https://www.cntk.ai/Models/SuperResolution/VDSR.model\", os.path.join(models_dir, \"VDSR.model\"))\n",
    "else:\n",
    "    print(\"Using cached VDSR model\")\n",
    "\n",
    "print(\"Loading models...\")\n",
    "VDSR_model = C.load_model(os.path.join(models_dir, \"VDSR.model\"))\n",
    "VDSR_trained_model = load_model(os.path.join(models_dir, \"vdsr_trained.hdf5\"))\n",
    "\n",
    "print(\"Loaded pretrained models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "def evaluate_pretrained(filename, outfile):\n",
    "    img = Image.open(filename)\n",
    "    model = VDSR_model\n",
    "    output_dims = 64\n",
    "\n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "\n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "\n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "\n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "\n",
    "    #pre-magnify picture if needed\n",
    "    img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "\n",
    "    #if the current image is being cleared up with no further uspcaling,\n",
    "    #set coef to 1 and other parameters accordingly\n",
    "    result = np.zeros((img.height, img.width, 3))\n",
    "    range_x = output_dims\n",
    "    range_y = output_dims\n",
    "    step_x = range_x - 2 * offset\n",
    "    step_y = range_y - 2 * offset\n",
    "    coef = 1\n",
    "\n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "\n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "\n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "\n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = np.squeeze(model.eval({model.arguments[0] : [rgb_patch]}))\n",
    "\n",
    "            img1 = np.ascontiguousarray(rgb_patch.transpose(2, 1, 0))\n",
    "            img2 = np.ascontiguousarray(pred.transpose(2, 1, 0))\n",
    "\n",
    "            #if model predicts residual image,\n",
    "            #scale back the prediction and add to starting patch\n",
    "            #otherwise just scale back\n",
    "            img2 = 255.0 * img2 + img1\n",
    "\n",
    "            # make sure img2 is C Contiguous as we just transposed it\n",
    "            img2 = np.ascontiguousarray(img2)\n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = C.relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "\n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "\n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "\n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "\n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad right\n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "\n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "\n",
    "    result = np.ascontiguousarray(result)\n",
    "\n",
    "    #save result\n",
    "    imsave(outfile, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filename - relative path of image being processed\n",
    "#outfile - relative path of the image which will be saved\n",
    "\n",
    "def evaluate_trained(filename, outfile):\n",
    "    model = VDSR_trained_model\n",
    "    output_dims = 64\n",
    "    img = Image.open(filename)\n",
    "\n",
    "    #upscaling coefficient\n",
    "    coef = 2\n",
    "\n",
    "    #at each step, we will evaluate subpatch (x : x + range_x, y : y + range_y) of original image\n",
    "    #patch by patch, we will resolve the whole image\n",
    "    range_x = output_dims // coef\n",
    "    range_y = output_dims // coef\n",
    "\n",
    "    #how many bounding pixels from resulting patch should be excluded?\n",
    "    #this is important because boundaries tend to be predicted less accurately\n",
    "    offset = output_dims // 10\n",
    "\n",
    "    #after we evaluate a subpatch, how much we move down/right to get the next one\n",
    "    #we subtract offset to cover those pixels which were boundary in the previous subpatch\n",
    "    step_x = range_x - offset\n",
    "    step_y = range_y - offset\n",
    "\n",
    "    img = img.resize((coef * img.width, coef * img.height), Image.BICUBIC)\n",
    "\n",
    "    result = np.zeros((img.height, img.width, 3))\n",
    "    range_x = output_dims\n",
    "    range_y = output_dims\n",
    "    step_x = range_x - 2 * offset\n",
    "    step_y = range_y - 2 * offset\n",
    "    coef = 1\n",
    "\n",
    "    rect = np.array(img, dtype = np.float32)\n",
    "\n",
    "    #if the image is too small for some models to work on it, pad it with zeros\n",
    "    if(rect.shape[0] < range_y):\n",
    "        pad = np.zeros((range_y - rect.shape[0], rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 0).astype(dtype = np.float32)\n",
    "\n",
    "    if(rect.shape[1] < range_x):\n",
    "        pad = np.zeros((rect.shape[0], range_x - rect.shape[1], rect.shape[2]))\n",
    "        rect = np.concatenate((rect, pad), axis = 1).astype(dtype = np.float32)\n",
    "\n",
    "    x = 0\n",
    "    y = 0\n",
    "    \n",
    "    #take subpatch by subpatch and resolve them to get the final image result\n",
    "    while(y < img.width):\n",
    "        x = 0\n",
    "        while(x < img.height):\n",
    "            rgb_patch = rect[x : x + range_x, y : y + range_y]\n",
    "            rgb_patch = rgb_patch[..., [2, 1, 0]]\n",
    "            rgb_patch = np.ascontiguousarray(np.rollaxis(rgb_patch, 2))\n",
    "            pred = model.predict(rgb_patch.transpose(2,1,0).reshape(1,64,64,3))\n",
    "\n",
    "            img2 = pred.reshape(64,64,3)\n",
    "\n",
    "            # make sure img2 is C Contiguous as we just transposed it\n",
    "            img2 = np.ascontiguousarray(img2)\n",
    "            #make sure no pixels are outside [0, 255] interval\n",
    "            for _ in range(2):\n",
    "                img2 = C.relu(img2).eval()\n",
    "                img2 = np.ones(img2.shape) * 255.0 - img2\n",
    "\n",
    "            rgb = img2[..., ::-1]\n",
    "            patch = rgb.transpose(1, 0, 2)\n",
    "\n",
    "            #fill in the pixels in the middle of the subpatch\n",
    "            #don't fill those within offset range to the boundary\n",
    "            for h in range(coef * x + offset, coef * x + output_dims - offset):\n",
    "                for w in range(coef * y + offset, coef * y + output_dims - offset):\n",
    "                    for col in range(0, 3):\n",
    "                        result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad top\n",
    "            if(x == 0):\n",
    "                for h in range(offset):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h][w - coef * y][col]\n",
    "\n",
    "            #pad left\n",
    "            if(y == 0):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(offset):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w][col]\n",
    "\n",
    "            #pad bottom\n",
    "            if(x == img.height - range_x):\n",
    "                for h in range(coef * img.height - offset, coef * img.height):\n",
    "                    for w in range(coef * y, coef * y + output_dims):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #pad right\n",
    "            if(y == img.width - range_y):\n",
    "                for h in range(coef * x, coef * x + output_dims):\n",
    "                    for w in range(coef * img.width - offset, coef * img.width):\n",
    "                        for col in range(0, 3):\n",
    "                            result[h][w][col] = patch[h - coef * x][w - coef * y][col]\n",
    "\n",
    "            #reached bottom of image\n",
    "            if(x == img.height - range_x):\n",
    "                break\n",
    "            #next step by x, we must not go out of bounds\n",
    "            x = min(x + step_x, img.height - range_x)\n",
    "\n",
    "        #reached right edge of image\n",
    "        if(y == img.width - range_x):\n",
    "            break\n",
    "        #next step by y, we must not go out of bounds\n",
    "        y = min(y + step_y, img.width - range_x)\n",
    "\n",
    "    result = np.ascontiguousarray(result)\n",
    "\n",
    "    #save result\n",
    "    imsave(outfile, result.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_folder = os.path.join(results_folder, \"bicubic\")\n",
    "\n",
    "#upscale by bicubic and save for reference\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    img = Image.open(filename)\n",
    "    out.save(os.path.join(save_folder, entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now creating: data\\vihance\\example_results\\VDSR_trained_results\\1525878424968.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aldi\\AppData\\Local\\Continuum\\Anaconda3\\envs\\py36\\lib\\site-packages\\cntk\\core.py:82: RuntimeWarning: data is not C contiguous; rearrange your data/computation to avoid costly data conversions\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time is 7.287409782409668 ms\n",
      "Now creating: data\\vihance\\example_results\\VDSR_trained_results\\253027.jpg\n",
      "Time is 3.8238871097564697 ms\n",
      "Now creating: data\\vihance\\example_results\\VDSR_pretrained_results\\1525878424968.jpg\n",
      "Time is 5.588998079299927 ms\n",
      "Now creating: data\\vihance\\example_results\\VDSR_pretrained_results\\253027.jpg\n",
      "Time is 3.4904215335845947 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "save_folder = os.path.join(results_folder, \"VDSR_trained_results\")\n",
    "\n",
    "#loop through every image in example_folder\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    outfile = os.path.join(save_folder, entry)\n",
    "\n",
    "    t = time.time()\n",
    "    print(\"Now creating: \" + outfile)\n",
    "\n",
    "    evaluate_trained(filename, outfile)\n",
    "\n",
    "    print(\"Time is {} ms\".format(time.time() - t))\n",
    "    \n",
    "save_folder = os.path.join(results_folder, \"VDSR_pretrained_results\")\n",
    "\n",
    "#loop through every image in example_folder\n",
    "for entry in os.listdir(example_folder):\n",
    "    filename = os.path.join(example_folder, entry)\n",
    "\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    outfile = os.path.join(save_folder, entry)\n",
    "\n",
    "    t = time.time()\n",
    "    print(\"Now creating: \" + outfile)\n",
    "\n",
    "    evaluate_pretrained(filename, outfile)\n",
    "\n",
    "    print(\"Time is {} ms\".format(time.time() - t))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
